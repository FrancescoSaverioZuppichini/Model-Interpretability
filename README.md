# Model-Interpretability
This is a public collection of papers related to machine learning model interpretability.

* [Detecting Bias in Black-Box Models Using Transparent Model Distillation](https://arxiv.org/pdf/1710.06169.pdf)
* [Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions](https://arxiv.org/pdf/1710.04806.pdf)
* [Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models](arxiv.org/pdf/1708.08296.pdf)
* [Visual Interpretability for Deep Learning: a Survey](https://arxiv.org/pdf/1802.00614.pdf)
* [A Survey Of Methods For Explaining Black Box Models](arxiv.org/pdf/1802.01933.pdf)
* [Manipulating and Measuring Model Interpretability](arxiv.org/pdf/1802.07810.pdf)
* [Interpretation of Neural Networks is Fragile](arxiv.org/pdf/1710.10547.pdf)
* [Interpretation of Prediction Models Using the Input Gradient](arxiv.org/pdf/1611.07634.pdf)
* [Programs as Black-Box Explanations](arxiv.org/pdf/1611.07579.pdf)
* ["I know it when I see it". Visualization and Intuitive Interpretability](arxiv.org/pdf/1711.08042.pdf)
* ["Why Should I Trust You?": Explaining the Predictions of Any Classifier](arxiv.org/pdf/1602.04938.pdf)
* [Beyond Sparsity: Tree Regularization of Deep Models for Interpretability](arxiv.org/pdf/1711.06178.pdf)
* [European Union regulations on algorithmic decision-making and a "right to explanation"](arxiv.org/pdf/1606.08813.pdf)
* [Explanation in Artificial Intelligence: Insights from the Social Sciences](arxiv.org/abs/1706.07269)
* [Extracting Thee-Structured Representations of Thained Networks](papers.nips.cc/paper/1152-extracting-tree-structured-representations-of-trained-networks.pdf)
* [Interpretability of Deep Learning Models: A Survey of Results](orca.cf.ac.uk/101500/1/Interpretability%20of%20Deep%20Learning%20Models%20-%20A%20Survey%20of%20Results.pdf)
* [Interpretable and Pedagogical Examples](arxiv.org/pdf/1711.00694.pdf)
* [Inverse Classification for Comparison-based Interpretability in Machine Learning](https://arxiv.org/pdf/1712.08443.pdf)
* [Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation](arxiv.org/pdf/1309.6392.pdf)
* [Show, Attend, Control, and Justify: Interpretable Learning for Self-Driving Cars](kimjinkyu.files.wordpress.com/2017/12/nips_2017.pdf)
* [The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification](arxiv.org/pdf/1503.01161.pdf)
* [The Doctor Just Won't Accept That!](arxiv.org/pdf/1711.08037.pdf)
* [The Intriguing Properties of Model Explanations](arxiv.org/pdf/1801.09808.pdf)
* [The Mythos of Model Interpretability](arxiv.org/pdf/1606.03490.pdf)
* [The Promise and Peril of Human Evaluation for Model Interpretability](arxiv.org/pdf/1711.07414.pdf)
* [Towards A Rigorous Science of Interpretable Machine Learning](arxiv.org/pdf/1702.08608.pdf)
* [TreeView: Peeking into Deep Neural Networks Via Feature-Space Partitioning](arxiv.org/pdf/1611.07429.pdf)
* [Using Visual Analytics to Interpret Predictive Machine Learning Models](arxiv.org/pdf/1606.05685.pdf)
* [Contextual Explanation Networks](arxiv.org/pdf/1705.10301.pdf)
